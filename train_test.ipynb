{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, './src')\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"1\"\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)\n",
    "import odl\n",
    "from odl.contrib.tensorflow import as_tensorflow_layer\n",
    "from odl.contrib import fom\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "from generate_data import generate_data\n",
    "from operators import operators_smooth, operators_nonsmooth\n",
    "from optimization import optimize\n",
    "\n",
    "# Start a tensorflow session\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.99)\n",
    "session = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = \"smooth\" # \"smooth\" or \"nonsmooth\"\n",
    "# smooth algorithms: \"learned_smooth\", \"nesterov\", \"steep_desc\"\n",
    "# nonsmooth algorithms: \"learned_nonsmooth\", \"ista\", \"fista\"\n",
    "algorithm = \"learned_smooth\" \n",
    "param_filename = \"\" \n",
    "batch_size = 1\n",
    "n_iter = 10\n",
    "val_ratio = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create operators\n",
    "if problem == \"smooth\":\n",
    "    T_odl, W_odl = operators_smooth()\n",
    "elif problem == \"nonsmooth\":\n",
    "    T_odl, W_odl = operators_nonsmooth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test, y_test = generate_data(T_odl, 'test', batch_size).__next__()\n",
    "plt.imshow(x_test[0].squeeze(), cmap='gray')\n",
    "plt.show()\n",
    "plt.imshow(y_test[0].squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_shape = (batch_size, T_odl.domain.shape[0], T_odl.domain.shape[1], 1)\n",
    "y_shape = (batch_size, T_odl.range.shape[0], T_odl.range.shape[1], 1)\n",
    "x = tf.placeholder(tf.float32, x_shape)\n",
    "y = tf.placeholder(tf.float32, y_shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "reconstruction, loss, loss_parts = optimize(algorithm, x, y, T_odl, W_odl, n_iter)\n",
    "tf.global_variables_initializer().run(session = session)\n",
    "if param_filename != \"\":\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
    "    train = optimizer.minimize(loss)\n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(session, param_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "reconstructed, final_loss, it_loss = \\\n",
    "        session.run([reconstruction, loss, loss_parts], feed_dict={x: np.zeros(x_shape), y: y_test}) \n",
    "\n",
    "elapsed_time = time.time() - start\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(x_test[0].squeeze(), clim=[0.8, 1.2], cmap='bone')\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(reconstructed[0].squeeze(), clim=[0.8, 1.2], cmap='bone')\n",
    "print(\"Final loss \", final_loss)\n",
    "print(\"Elapsed time \", elapsed_time, \", average time \", elapsed_time / n_iter)\n",
    "print(\"PSNR \", fom.psnr(reconstructed, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f + g\n",
    "plt.loglog(it_loss[0] + it_loss[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(it_loss) > 2: \n",
    "    plt.loglog(it_loss[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run tests\n",
    "generator_test = generate_data(T_odl, 'test', batch_size)\n",
    "res_filename = './results/mayo/'+str(algorithm)+\"_\"+ str(n_iter)+\"_opt_iter.dat\"\n",
    "if os.path.exists(res_filename):\n",
    "    os.remove(res_filename)\n",
    "\n",
    "i = 0\n",
    "for batch in generator_test.__iter__():\n",
    "    x_test, y_test = batch\n",
    "    reconstructed, final_loss, it_loss = \\\n",
    "        session.run([reconstruction, loss, loss_parts], feed_dict={x: np.zeros(x_shape), y: y_test}) \n",
    "    print(\"Iteration \",i,\"------------------------\")\n",
    "    print(\"Final loss \", final_loss)\n",
    "    print(\"Loss parts\", it_loss[0][0], it_loss[0][n_iter-1], it_loss[1][0], it_loss[1][n_iter-1])\n",
    "\n",
    "    # save loss info to file\n",
    "    if res_filename != \"\":\n",
    "        f = open(res_filename,'ab')\n",
    "        np.savetxt(f,(it_loss[0], it_loss[1]))\n",
    "        f.close()\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "res_filename = './models/mayo/'+str(algorithm)+\"_\"\n",
    "# sample number of iterations\n",
    "n_iter_rand = tf.constant(n_iter, dtype=tf.int32) + tf.random_uniform([],minval=0, maxval=n_iter,dtype=tf.int32)\n",
    "reconstruction, loss, loss_parts = optimize(algorithm, x, y, T_odl, W_odl, n_iter_rand)\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=1e-3)\n",
    "    train = optimizer.minimize(loss)\n",
    "tf.global_variables_initializer().run(session = session)\n",
    "saver = tf.train.Saver()\n",
    "if param_filename != \"\":\n",
    "    saver.restore(session, param_filename)\n",
    "    \n",
    "# Summaries\n",
    "time_str = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "summary_path = './log/' + time_str\n",
    "if not os.path.exists(summary_path):\n",
    "    os.makedirs(summary_path)\n",
    "tf.summary.scalar('loss', loss)\n",
    "summary = tf.summary.merge_all()\n",
    "test_log = tf.summary.FileWriter(summary_path + '/test', session.graph)\n",
    "train_log = tf.summary.FileWriter(summary_path + '/train')\n",
    "\n",
    "generator_train = generate_data(T_odl, 'train', batch_size, val_ratio=0.01)\n",
    "for i in range(100001):\n",
    "    x_train, y_train = generator_train.__next__()\n",
    "    _, summ = session.run([train, summary], feed_dict={x: np.zeros(x_shape), y: y_train})\n",
    "    train_log.add_summary(summ, i)\n",
    "    if i % 1000 == 0:\n",
    "        print('iter={}/100000'.format(i))\n",
    "        val_loss = 0\n",
    "        j = 0\n",
    "        generator_val = generate_data(T_odl, 'validate', batch_size, val_ratio=0.01)\n",
    "        for val_batch in generator_val.__iter__():\n",
    "            x_validate, y_validate = val_batch\n",
    "            reconstructed, loss_batch, summ = \\\n",
    "                session.run([reconstruction, loss, summary], feed_dict={x: np.zeros(x_shape), y: y_validate})\n",
    "            val_loss += loss_batch\n",
    "            test_log.add_summary(summ, i)\n",
    "            j = j + 1\n",
    "        val_loss /= float(j) \n",
    "        print(\"Validation loss \", val_loss)\n",
    "    if i % 10000 == 0:\n",
    "        if res_filename != \"\":\n",
    "            save_path = saver.save(session, res_filename + str(i)+\"_train_iter.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python37",
   "language": "python",
   "name": "python37"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
